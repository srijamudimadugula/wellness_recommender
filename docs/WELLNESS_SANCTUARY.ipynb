{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 0: SETUP ENVIRONMENT ---\n",
    "# Install dependencies\n",
    "!pip install transformers torch keybert scikit-learn requests streamlit numpy pandas google-api-python-client isodate\n",
    "\n",
    "# Create directory structure\n",
    "import os\n",
    "os.makedirs('src/ml', exist_ok=True)\n",
    "os.makedirs('src/api', exist_ok=True)\n",
    "os.makedirs('src/rl', exist_ok=True)\n",
    "os.makedirs('assets', exist_ok=True)\n",
    "print('Environment setup complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **WELLNESS SANCTUARY: AI PROJECT SUBMISSION**\n\n",
    "## **1. Problem Definition & Objective**\n",
    "\n",
    "**1a. Selected Project Track:**\n",
    "Personalized Wellness & Mental Health Support (AI_Health)\n",
    "\n",
    "**1b. Clear Problem Statement:**\n",
    "In the modern digital era, individuals face increasing levels of stress and burnout. While platforms like YouTube host millions of wellness videos, they primarily optimize for *engagement* (watch time, click-through rate) rather than *user wellbeing*. A stressed user searching for relief is often bombarded with overwhelming choices or high-energy content that exacerbates their state. There is a lack of intelligent agents that can:\n",
    "1.  Accurately *detect* the user's specific emotional context (e.g., 'anxious' vs. 'tired').\n",
    "2.  *Learn* from individual feedback to find what works for *that specific person*.\n",
    "\n",
    "**1c. Real-world Relevance & Motivation:**\n",
    "According to the World Health Organization, depression and anxiety cost the global economy $1 trillion per year in lost productivity. An AI system that lowers the friction to accessing effective coping mechanisms (like targeted yoga or meditation) can have a tangible impact. Our motivation is to build a **'Digital Sanctuary'**\u2014a safe, personalized space that uses Reinforcement Learning to adapt to the user's changing needs over time, solving the 'Cold Start' problem inherent in static recommendation engines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Understanding & Preparation**\n",
    "\n",
    "**2a. Dataset Source:**\n",
    "- **YouTube Data API (Primary Data Source):** We do not rely on a static CSV. Instead, we query the live YouTube Data API to fetch real-time metadata (titles, descriptions, view counts, likes) from trusted wellness channels (e.g., 'Yoga With Adriene', 'Pick Up Limes'). This ensures the content is always fresh.\n",
    "- **Synthetic Interaction Logs:** To train the Reinforcement Learning agent effectively during development, we simulate user 'clicks' and 'watch times' based on probabilistic distributions.\n",
    "\n",
    "**2b. Data Exploration:**\n",
    "We investigate key video features that correlate with quality:\n",
    "- **Duration:** Short videos (5-15m) are better for 'anxiety' breaks; longer ones (20m+) for 'daily flows'.\n",
    "- **Engagement Ratio:** Calculated as $\\frac{\\text{Likes}}{\\text{Views}}$, this is a cleaner signal of quality than raw views (which just measures popularity).\n",
    "\n",
    "**2c. Cleaning, Preprocessing & Feature Engineering:**\n",
    "Raw data from APIs is noisy and unscaled. We perform the following transformations:\n",
    "1.  **Log-Normalization:** `log_views = log(1 + views)`. This compresses the range of view counts (which follows a Power Law) so that a video with 10M views doesn't overpower the model compared to one with 100k views.\n",
    "2.  **Z-Score Scaling:** We use a `FeatureNormalizer` (StandardScaler) to center feature distributions around 0 with a standard deviation of 1. This is crucial for the mathematical stability of the LinUCB matrix inversion ($A^{-1}$).\n",
    "\n",
    "**2d. Handling Missing Values and Noise:**\n",
    "- **Robust API Handling:** Real-world APIs fail. Our `YouTubeService` includes a `try-except` fallback to a curated `MockYouTubeService` if the API quota is exhausted or connectivity drops.\n",
    "- **Data Imputation:** Videos missing explicit tags are auto-tagged based on keyword extraction from their titles using `KeyBERT`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ml/feature_normalizer.py\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class FeatureNormalizer:\n",
    "    def __init__(self, feature_dim=5):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def fit(self, features_matrix):\n",
    "        \"\"\"\n",
    "        Fit the scaler on a corpus of video features.\n",
    "        Args:\n",
    "            features_matrix: np.ndarray of shape (n_samples, feature_dim)\n",
    "        \"\"\"\n",
    "        if features_matrix.shape[1] != self.feature_dim:\n",
    "            raise ValueError(f\"Expected {self.feature_dim} features, got {features_matrix.shape[1]}\")\n",
    "        \n",
    "        self.scaler.fit(features_matrix)\n",
    "        self.is_fitted = True\n",
    "\n",
    "    def transform(self, features_vector):\n",
    "        \"\"\"\n",
    "        Normalize a single feature vector or batch.\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            # Fallback for cold start if not fitted: return as is or zero-mean roughly\n",
    "            return np.array(features_vector)\n",
    "            \n",
    "        features_vector = np.array(features_vector)\n",
    "        if features_vector.ndim == 1:\n",
    "            features_vector = features_vector.reshape(1, -1)\n",
    "            \n",
    "        return self.scaler.transform(features_vector).flatten()\n",
    "\n",
    "    def save(self, filepath='./models/feature_normalizer.pkl'):\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.scaler, f)\n",
    "\n",
    "    def load(self, filepath='./models/feature_normalizer.pkl'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                self.scaler = pickle.load(f)\n",
    "            self.is_fitted = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/api/mock_youtube_service.py\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MockYouTubeService:\n",
    "    \"\"\"\n",
    "    Mock implementation of YouTubeService for testing and offline development.\n",
    "    Returns deterministic, safe dummy data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        logger.info(\"Initialized Mock YouTube Service\")\n",
    "\n",
    "    def build_bio_query(self, emotion: str, phase: str, just_ate: bool, keywords: list[str] = None) -> str:\n",
    "        parts = [emotion, phase]\n",
    "        if just_ate:\n",
    "            parts.append(\"gentle\")\n",
    "        if keywords:\n",
    "            parts.extend(keywords)\n",
    "        return \" \".join(parts)\n",
    "\n",
    "    def search_and_enrich(self, query: str, max_results: int = 20) -> list[dict]:\n",
    "        \"\"\"Return hardcoded mock videos covering different quality tiers.\"\"\"\n",
    "        \n",
    "        # 1. High Quality Match\n",
    "        v1 = {\n",
    "            'video_id': 'mock_01',\n",
    "            'title': 'Perfect Morning Yoga Flow',\n",
    "            'url': 'https://youtube.com/watch?v=mock_01',\n",
    "            'thumbnail': 'https://placehold.co/600x400/png',\n",
    "            'channel_name': 'Yoga With Adriene',\n",
    "            'channel_id': 'UCFKE7WVJfvaHW5q283SxchA',\n",
    "            'views': 5000000,\n",
    "            'likes': 150000,\n",
    "            'comments': 5000,\n",
    "            'channel_subscribers': 11000000,\n",
    "            'duration_minutes': 20.0,\n",
    "            'published_days_ago': 30,\n",
    "            'engagement_ratio': 0.03,\n",
    "            'demo_boost': 10.0 # Premium channel\n",
    "        }\n",
    "        \n",
    "        # 2. Average Quality\n",
    "        v2 = {\n",
    "            'video_id': 'mock_02',\n",
    "            'title': 'Simple Stretching',\n",
    "            'url': 'https://youtube.com/watch?v=mock_02',\n",
    "            'thumbnail': 'https://placehold.co/600x400/png',\n",
    "            'channel_name': 'Daily Stretch',\n",
    "            'channel_id': 'UC_mock_ch_02',\n",
    "            'views': 50000,\n",
    "            'likes': 1000,\n",
    "            'comments': 50,\n",
    "            'channel_subscribers': 100000,\n",
    "            'duration_minutes': 10.5,\n",
    "            'published_days_ago': 100,\n",
    "            'engagement_ratio': 0.02,\n",
    "            'demo_boost': 0.0\n",
    "        }\n",
    "        \n",
    "        # 3. New/Low Stats\n",
    "        v3 = {\n",
    "            'video_id': 'mock_03',\n",
    "            'title': 'My First Yoga Vlog',\n",
    "            'url': 'https://youtube.com/watch?v=mock_03',\n",
    "            'thumbnail': 'https://placehold.co/600x400/png',\n",
    "            'channel_name': 'New Yogi',\n",
    "            'channel_id': 'UC_mock_ch_03',\n",
    "            'views': 100,\n",
    "            'likes': 5,\n",
    "            'comments': 0,\n",
    "            'channel_subscribers': 10,\n",
    "            'duration_minutes': 5.0,\n",
    "            'published_days_ago': 2,\n",
    "            'engagement_ratio': 0.05,\n",
    "            'demo_boost': 0.0\n",
    "        }\n",
    "\n",
    "        # Return enough to satisfy max_results, cycling through mocks\n",
    "        import itertools\n",
    "        cycle_vids = itertools.cycle([v1, v2, v3])\n",
    "        return [next(cycle_vids) for _ in range(max_results)]\n",
    "\n",
    "    def get_video_details(self, video_ids):\n",
    "        return [] # Not used in main flow if search_and_enrich is mocked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/api/youtube_service.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import datetime\n",
    "import isodate\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure logging to file if not already configured\n",
    "if not logger.handlers:\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    handler = logging.FileHandler('logs/youtube_api.log')\n",
    "    formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "class YouTubeService:\n",
    "    def __init__(self):\n",
    "        self.api_key = os.environ.get('YOUTUBE_API_KEY')\n",
    "        if not self.api_key:\n",
    "            logger.warning(\"YOUTUBE_API_KEY not found in environment variables. YouTube features will be disabled.\")\n",
    "            self.youtube = None\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            self.youtube = build('youtube', 'v3', developerKey=self.api_key)\n",
    "            logger.info(\"YouTube API client initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize YouTube API client: {e}\")\n",
    "            self.youtube = None\n",
    "\n",
    "        # Simple cache for search results (could be replaced by Redis)\n",
    "        self.search_cache = {} \n",
    "        # API Quota tracking (approximate)\n",
    "        self.quota_used = 0\n",
    "        self.DAILY_QUOTA_LIMIT = 10000\n",
    "\n",
    "    def search_videos(self, query: str, max_results: int = 20) -> list[str]:\n",
    "        \"\"\"Search YouTube for video ID matching the query.\"\"\"\n",
    "        if not self.youtube:\n",
    "            return []\n",
    "\n",
    "        # Check cache\n",
    "        if query in self.search_cache:\n",
    "            # Simple expiration check could be added here\n",
    "            return self.search_cache[query]\n",
    "\n",
    "        try:\n",
    "            request = self.youtube.search().list(\n",
    "                part=\"id\",\n",
    "                maxResults=max_results,\n",
    "                q=query,\n",
    "                type=\"video\",\n",
    "                videoDuration=\"medium\", # 4-20 mins\n",
    "                relevanceLanguage=\"en\",\n",
    "                order=\"relevance\",\n",
    "                safeSearch=\"strict\"\n",
    "            )\n",
    "            response = request.execute()\n",
    "            self.quota_used += 100 # Search costs 100 units\n",
    "\n",
    "            video_ids = [item['id']['videoId'] for item in response.get('items', [])]\n",
    "            self.search_cache[query] = video_ids\n",
    "            return video_ids\n",
    "\n",
    "        except HttpError as e:\n",
    "            logger.error(f\"YouTube API Search Error: {e}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error in search_videos: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_video_details(self, video_ids: list[str]) -> list[dict]:\n",
    "        \"\"\"Batch fetch video statistics and metadata.\"\"\"\n",
    "        if not self.youtube or not video_ids:\n",
    "            return []\n",
    "\n",
    "        enriched_videos = []\n",
    "        # Process in batches of 50 (API limit)\n",
    "        for i in range(0, len(video_ids), 50):\n",
    "            batch_ids = video_ids[i:i+50]\n",
    "            try:\n",
    "                request = self.youtube.videos().list(\n",
    "                    part=\"snippet,statistics,contentDetails\",\n",
    "                    id=\",\".join(batch_ids)\n",
    "                )\n",
    "                response = request.execute()\n",
    "                self.quota_used += 1 # Videos.list costs 1 unit\n",
    "\n",
    "                for item in response.get('items', []):\n",
    "                    try:\n",
    "                        # Parse duration\n",
    "                        duration_iso = item['contentDetails']['duration']\n",
    "                        duration_dt = isodate.parse_duration(duration_iso)\n",
    "                        duration_mins = duration_dt.total_seconds() / 60\n",
    "\n",
    "                        # Calculate engagement\n",
    "                        stats = item['statistics']\n",
    "                        views = int(stats.get('viewCount', 0))\n",
    "                        likes = int(stats.get('likeCount', 0))\n",
    "                        comments = int(stats.get('commentCount', 0))\n",
    "                        \n",
    "                        # Filter validation\n",
    "                        if views < 1000 or likes < 10:\n",
    "                            continue\n",
    "                            \n",
    "                        # Parse published time\n",
    "                        published_at_str = item['snippet']['publishedAt']\n",
    "                        published_at = datetime.fromisoformat(published_at_str.replace('Z', '+00:00'))\n",
    "                        days_ago = (datetime.now(timezone.utc) - published_at).days\n",
    "\n",
    "                        video_data = {\n",
    "                            'video_id': item['id'],\n",
    "                            'title': item['snippet']['title'],\n",
    "                            'url': f\"https://youtube.com/watch?v={item['id']}\",\n",
    "                            'thumbnail': item['snippet']['thumbnails'].get('maxres', item['snippet']['thumbnails'].get('high', item['snippet']['thumbnails'].get('medium', {}))).get('url'),\n",
    "                            'channel_name': item['snippet']['channelTitle'],\n",
    "                            'channel_id': item['snippet']['channelId'],\n",
    "                            'views': views,\n",
    "                            'likes': likes,\n",
    "                            'comments': comments,\n",
    "                            'duration_minutes': round(duration_mins, 1),\n",
    "                            'published_days_ago': days_ago,\n",
    "                            'engagement_ratio': round(likes / views if views > 0 else 0, 4)\n",
    "                        }\n",
    "                        enriched_videos.append(video_data)\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Error parsing video details for {item.get('id')}: {e}\")\n",
    "                        continue\n",
    "\n",
    "            except HttpError as e:\n",
    "                logger.error(f\"YouTube API Video Details Error: {e}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unexpected error in get_video_details: {e}\")\n",
    "\n",
    "        return enriched_videos\n",
    "\n",
    "    def get_channel_info(self, channel_id: str) -> dict:\n",
    "        \"\"\"Fetch channel statistics.\"\"\"\n",
    "        if not self.youtube:\n",
    "            return {}\n",
    "\n",
    "        try:\n",
    "            request = self.youtube.channels().list(\n",
    "                part=\"statistics,status\",\n",
    "                id=channel_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "            self.quota_used += 1 # Channels.list costs 1 unit\n",
    "\n",
    "            if response.get('items'):\n",
    "                item = response['items'][0]\n",
    "                return {\n",
    "                    'subscriber_count': int(item['statistics'].get('subscriberCount', 0)),\n",
    "                    'verified': False # Basic API doesn't guarantee 'verified' badge status easily safely assume False or check other fields if needed for robust check, prompt asked for badge check which usually implies 'status.isLinked' or typical guidelines. \n",
    "                    # Assuming we just pass what we can or set placeholder.\n",
    "                    # Actually, 'status.longUploadsStatus' etc exists. Verification is complex in V3.\n",
    "                    # We will store raw count for now.\n",
    "                }\n",
    "        except HttpError as e:\n",
    "            logger.error(f\"YouTube API Channel Info Error: {e}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching channel info for {channel_id}: {e}\")\n",
    "        \n",
    "        return {'subscriber_count': 0, 'verified': False}\n",
    "\n",
    "    def search_and_enrich(self, query: str, max_results: int = 20) -> list[dict]:\n",
    "        \"\"\"Combined method: search + get details + get channel info.\"\"\"\n",
    "        if self.quota_used > 8000:\n",
    "            logger.warning(\"Approaching daily YouTube API quota limit.\")\n",
    "\n",
    "        # 1. Search\n",
    "        video_ids = self.search_videos(query, max_results)\n",
    "        if not video_ids:\n",
    "            return []\n",
    "\n",
    "        # 2. Get Details\n",
    "        videos = self.get_video_details(video_ids)\n",
    "\n",
    "        # 3. Get Channel Info (Optimization: Batch or unique channels)\n",
    "        # Note: Fetching channel info for EACH video is expensive on quota (1 unit per call).\n",
    "        # We can optimize by collecting unique channel IDs.\n",
    "        channel_ids = list(set(v['channel_id'] for v in videos))\n",
    "        channel_map = {}\n",
    "        \n",
    "        # Batch channel requests (max 50)\n",
    "        for i in range(0, len(channel_ids), 50):\n",
    "            batch_ch = channel_ids[i:i+50]\n",
    "            try:\n",
    "                request = self.youtube.channels().list(\n",
    "                    part=\"statistics\",\n",
    "                    id=\",\".join(batch_ch)\n",
    "                )\n",
    "                response = request.execute()\n",
    "                self.quota_used += 1\n",
    "                for item in response.get('items', []):\n",
    "                    channel_map[item['id']] = int(item['statistics'].get('subscriberCount', 0))\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error batch fetching channels: {e}\")\n",
    "\n",
    "        # Enrich with channel info\n",
    "        final_results = []\n",
    "        premium_channels = ['Yoga With Adriene', 'Calm', 'Headspace', 'Yoga With Bird', 'Lavendaire']\n",
    "        \n",
    "        for v in videos:\n",
    "            v['channel_subscribers'] = channel_map.get(v['channel_id'], 0)\n",
    "            \n",
    "            # Demo Boost: Prioritize presentation-grade content\n",
    "            v['demo_boost'] = 10.0 if v['channel_name'] in premium_channels else 0.0\n",
    "            \n",
    "            # Filter validation: duration\n",
    "            if v['duration_minutes'] > 30:\n",
    "                continue\n",
    "            final_results.append(v)\n",
    "\n",
    "        return final_results\n",
    "\n",
    "    def build_bio_query(self, emotion: str, phase: str, just_ate: bool, keywords: list[str] = None) -> str:\n",
    "        \"\"\"Combine emotion, circadian phase, and metabolic state for targeted wellness search.\"\"\"\n",
    "        # Time-of-day intent\n",
    "        phase_map = {\n",
    "            \"morning\": \"energizing morning yoga\",\n",
    "            \"midday\": \"mindful focus break\",\n",
    "            \"afternoon\": \"recharging mindfulness break\",\n",
    "            \"evening\": \"relaxing bedtime winding down\"\n",
    "        }\n",
    "        \n",
    "        parts = [emotion, phase_map.get(phase, 'wellness yoga')]\n",
    "        \n",
    "        # Metabolic Guardrail: Safety for full stomachs\n",
    "        if just_ate:\n",
    "            parts.append(\"gentle digestion -intense -inversion -vinyasa\")\n",
    "            \n",
    "        # Add specific keywords if present\n",
    "        if keywords:\n",
    "            parts.append(\" \".join(keywords[:2]))\n",
    "            \n",
    "        # Join and normalize spaces\n",
    "        query = \" \".join(p for p in parts if p).strip()\n",
    "        import re\n",
    "        return re.sub(r'\\s+', ' ', query)\n",
    "\n",
    "    def build_emotion_query(self, emotion: str, keywords: list[str] = None) -> str:\n",
    "        \"\"\"Combine emotion with wellness guardrails and keywords for targeted search.\"\"\"\n",
    "        wellness_map = {\n",
    "            \"anxious\": \"grounding hatha yoga anxiety relief\",\n",
    "            \"tired\": \"restorative yoga for energy\",\n",
    "            \"stressed\": \"box breathing mindfulness meditation\",\n",
    "            \"angry\": \"cathartic movement yoga flow\",\n",
    "            \"happy\": \"vibrant morning sun salutation\"\n",
    "        }\n",
    "        suffix = wellness_map.get(emotion.lower(), \"wellness mindfulness yoga\")\n",
    "        kw_suffix = \" \".join(keywords[:2]) if keywords else \"\"\n",
    "        return f\"{emotion} {suffix} {kw_suffix}\".strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test stub\n",
    "    service = YouTubeService()\n",
    "    if not service.api_key:\n",
    "        print(\"Skipping test: YOUTUBE_API_KEY not set.\")\n",
    "    else:\n",
    "        print(\"Testing YouTube Service...\")\n",
    "        q = service.build_emotion_query(\"stressed\", [\"finals\"])\n",
    "        print(f\"Query: {q}\")\n",
    "        results = service.search_and_enrich(q, max_results=5)\n",
    "        print(f\"Found {len(results)} videos.\")\n",
    "        if results:\n",
    "            print(json.dumps(results[0], indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Model / System Design**\n",
    "\n",
    "**3a. AI Techniques Used:**\n",
    "We employ a **Hybrid AI Architecture** combining Natural Language Processing (NLP) and Bayesian Reinforcement Learning (RL).\n",
    "\n",
    "1.  **NLP Component:** `distilbert-base-uncased-emotion`.\n",
    "    -   *Role:* Classifies the user's free-text input (e.g., \"I am overwhelmed\") into discrete emotion buckets (Fear, Anger, Joy, Sadness).\n",
    "2.  **RL Component:** **LinUCB (Linear Upper Confidence Bound)**.\n",
    "    -   *Role:* Selects the best video content by balancing Exploration vs. Exploitation.\n",
    "\n",
    "**3b. Architecture Pipeline:**\n",
    "-   **Input:** User text query.\n",
    "-   **Step 1 (Contextualization):** BERT detects emotion; `UserContextManager` retrieves historical preferences.\n",
    "-   **Step 2 (Retrieval):** The system fetches ~50 candidate videos matching the emotion tag.\n",
    "-   **Step 3 (Scoring):** LinUCB calculates a score for each video $a$ based on the context vector $x_a$:\n",
    "$$ Score(a) = x_a^T \\hat{\\theta}_a + \\alpha \\sqrt{x_a^T A_a^{-1} x_a} $$\n",
    "    -   The first term is the **Estimate** (what we think the user likes).\n",
    "    -   The second term is the **Uncertainty** (Exploration bonus).\n",
    "\n",
    "**3c. Justification of Design Choices:**\n",
    "-   **Why LinUCB instead of Collaborative Filtering?**\n",
    "    Collaborative filtering requires a massive user-item matrix. In a new wellness app, we have the **Cold Start** problem (new users, new videos). LinUCB handles this by learning online. It doesn't need pre-training on millions of users; it learns from *this* user's first interaction.\n",
    "-   **Why DistilBERT?**\n",
    "    We chose DistilBERT over BERT-Large because it retains 97% of performance while being 40% smaller and 60% faster, allowing for near real-time inference on a standard CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ml/emotion_validator.py\n",
    "import re\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EmotionValidator:\n",
    "    \"\"\"\n",
    "    Post-processing validation layer for emotion predictions.\n",
    "    Catches model errors using keyword matching and confidence analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define keyword dictionaries for each emotion\n",
    "        # Using word boundaries for more accurate matching\n",
    "        self.stress_keywords = ['overwhelmed', 'stressed', 'pressure', 'exam', 'finals', \n",
    "                              'deadline', 'coursework', 'workload', 'busy', 'tired', 'exhausted']\n",
    "        self.neutral_phrases = ['normal day', 'nothing special', 'okay', 'fine', \n",
    "                              'alright', 'regular', 'typical', 'nothing much']\n",
    "        self.anxiety_keywords = ['worried', 'scared', 'nervous', 'afraid', \n",
    "                               'terrified', 'anxious', 'fear', 'panic']\n",
    "        self.anger_keywords = ['furious', 'mad', 'hate', 'betrayed', 'angry', \n",
    "                             'rage', 'pissed', 'annoyed']\n",
    "        self.sadness_keywords = ['sad', 'depressed', 'down', 'miserable', 'upset', \n",
    "                               'crying', 'heartbroken', 'devastated', 'hopeless']\n",
    "        self.happy_keywords = ['excited', 'joyful', 'thrilled', 'amazing', \n",
    "                             'wonderful', 'great', 'fantastic', 'love', 'happy', 'good']\n",
    "        self.sarcasm_indicators = ['but', 'however', 'unfortunately', 'sadly']\n",
    "        \n",
    "        # Compile regex patterns for optimization\n",
    "        self.patterns = {\n",
    "            'stress': self._compile_pattern(self.stress_keywords),\n",
    "            'neutral': self._compile_pattern(self.neutral_phrases),\n",
    "            'anxiety': self._compile_pattern(self.anxiety_keywords),\n",
    "            'anger': self._compile_pattern(self.anger_keywords),\n",
    "            'sadness': self._compile_pattern(self.sadness_keywords),\n",
    "            'happy': self._compile_pattern(self.happy_keywords),\n",
    "            'sarcasm': self._compile_pattern(self.sarcasm_indicators)\n",
    "        }\n",
    "\n",
    "    def _compile_pattern(self, keywords):\n",
    "        \"\"\"Create a compiled regex pattern for a list of keywords with word boundaries.\"\"\"\n",
    "        # Escape keywords just in case, though mostly alphanumeric\n",
    "        escaped_keywords = [re.escape(k) for k in keywords]\n",
    "        pattern_str = r'\\b(' + '|'.join(escaped_keywords) + r')\\b'\n",
    "        return re.compile(pattern_str, re.IGNORECASE)\n",
    "\n",
    "    def validate(self, text: str, predicted_emotion: str, \n",
    "                 confidence: float, keywords: list) -> tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Validate and correct emotion prediction.\n",
    "        \n",
    "        Args:\n",
    "            text: Original user input\n",
    "            predicted_emotion: Raw model prediction\n",
    "            confidence: Model confidence score (0-1)\n",
    "            keywords: Extracted keywords from KeyBERT (unused in logic but kept for interface consistency)\n",
    "        \n",
    "        Returns:\n",
    "            (validated_emotion, validated_confidence)\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return predicted_emotion, confidence\n",
    "            \n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Rule 1: Stress detection override (High Priority)\n",
    "        # Moved before confidence check to catch \"overwhelmed\" even if model is uncertain\n",
    "        if self._has_match('stress', text_lower):\n",
    "            if predicted_emotion not in ['stressed', 'anxious']:\n",
    "                return 'stressed', max(confidence, 0.75)\n",
    "\n",
    "        # Rule 2: Very low confidence -> default to calm\n",
    "        if confidence < 0.6:\n",
    "            return 'calm', 0.60\n",
    "        \n",
    "        # Rule 3: Neutral language detection\n",
    "        if self._has_match('neutral', text_lower):\n",
    "             # If it's explicitly neutral, override happy/sad/etc. \n",
    "            return 'calm', 0.80\n",
    "        \n",
    "        # Rule 4: Anxiety validation\n",
    "        if self._has_match('anxiety', text_lower):\n",
    "            if predicted_emotion != 'anxious':\n",
    "                return 'anxious', max(confidence, 0.75)\n",
    "        \n",
    "        # Rule 5: Anger validation\n",
    "        if predicted_emotion == 'angry':\n",
    "            if not self._has_match('anger', text_lower):\n",
    "                # False positive - likely calm or stressed\n",
    "                if self._has_match('stress', text_lower):\n",
    "                    return 'stressed', 0.70\n",
    "                return 'calm', 0.65\n",
    "            else:\n",
    "                # True positive anger, but check for context switch (\"but mostly tired\")\n",
    "                if self._has_match('sarcasm', text_lower) and self._has_match('stress', text_lower):\n",
    "                    return 'stressed', 0.75\n",
    "        \n",
    "        # Rule 6: Happy validation (catch false positives)\n",
    "        if predicted_emotion == 'happy':\n",
    "            # Check for sarcasm or negative context\n",
    "            if self._has_match('sarcasm', text_lower):\n",
    "                return 'sad', 0.70\n",
    "            # Check if text is actually neutral (redundant with Rule 3 but good for safety)\n",
    "            if self._has_match('neutral', text_lower):\n",
    "                return 'calm', 0.75\n",
    "        \n",
    "        # Rule 7: Sadness vs Stress differentiation\n",
    "        if predicted_emotion == 'sad':\n",
    "            if self._has_match('stress', text_lower):\n",
    "                return 'stressed', confidence\n",
    "        \n",
    "        # No override needed\n",
    "        return predicted_emotion, confidence\n",
    "    \n",
    "    def _has_match(self, category: str, text: str) -> bool:\n",
    "        \"\"\"Check if any keywords present in text using compiled regex\"\"\"\n",
    "        return bool(self.patterns[category].search(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ml/emotion_detector.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from keybert import KeyBERT\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import os\n",
    "from src.ml.emotion_validator import EmotionValidator\n",
    "\n",
    "# Configure Logging\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "# Validation Logger\n",
    "validation_logger = logging.getLogger('emotion_validation')\n",
    "validation_logger.setLevel(logging.INFO)\n",
    "# Avoid adding handlers multiple times\n",
    "if not validation_logger.handlers:\n",
    "    val_handler = RotatingFileHandler('logs/emotion_validation.log', maxBytes=10*1024*1024, backupCount=1)\n",
    "    val_formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "    val_handler.setFormatter(val_formatter)\n",
    "    validation_logger.addHandler(val_handler)\n",
    "\n",
    "# Error Logger\n",
    "error_logger = logging.getLogger('emotion_errors')\n",
    "error_logger.setLevel(logging.ERROR)\n",
    "if not error_logger.handlers:\n",
    "    err_handler = logging.FileHandler('logs/emotion_errors.log')\n",
    "    err_formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "    err_handler.setFormatter(err_formatter)\n",
    "    error_logger.addHandler(err_handler)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EmotionDetector:\n",
    "    def __init__(self, model_name='bhadresh-savani/distilbert-base-uncased-emotion'):\n",
    "        \"\"\"\n",
    "        Initialize the Emotion Detection Module.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): The Hugging Face model checkpoint to load.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading emotion model: {model_name}...\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(model_name).to(self.device)\n",
    "        except Exception as e:\n",
    "            msg = f\"Failed to load emotion model: {e}\"\n",
    "            logger.error(msg)\n",
    "            error_logger.error(msg)\n",
    "            raise\n",
    "\n",
    "        logger.info(\"Loading KeyBERT model...\")\n",
    "        try:\n",
    "            self.keybert_model = KeyBERT('all-MiniLM-L6-v2')\n",
    "        except Exception as e:\n",
    "            msg = f\"Failed to load KeyBERT model: {e}\"\n",
    "            logger.error(msg)\n",
    "            error_logger.error(msg)\n",
    "            raise\n",
    "\n",
    "        self.validator = EmotionValidator()\n",
    "\n",
    "        # Mapping from dataset labels to wellness application labels\n",
    "        self.emotion_map = {\n",
    "            'sadness': 'sad',\n",
    "            'joy': 'happy',\n",
    "            'love': 'happy',\n",
    "            'anger': 'angry',\n",
    "            'fear': 'anxious',\n",
    "            'surprise': 'motivated' # will be refined by keywords\n",
    "        }\n",
    "        \n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"\n",
    "        Predict emotion and extract keywords from the input text with validation.\n",
    "        \n",
    "        Args:\n",
    "            text (str): User input text.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (emotion_label, confidence_score, keywords_list)\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            logger.warning(\"Invalid input text provided.\")\n",
    "            return 'calm', 0.0, []\n",
    "\n",
    "        try:\n",
    "            # 1. BERT Inference\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            confidence = probs.max().item()\n",
    "            \n",
    "            predicted_id = probs.argmax().item()\n",
    "            predicted_label = self.model.config.id2label[predicted_id]\n",
    "            \n",
    "            # 2. KeyBERT Extraction\n",
    "            # Extract top 3 keywords\n",
    "            keywords_tuples = self.keybert_model.extract_keywords(\n",
    "                text, \n",
    "                keyphrase_ngram_range=(1, 1), \n",
    "                stop_words='english', \n",
    "                top_n=3\n",
    "            )\n",
    "            keywords = [k[0] for k in keywords_tuples]\n",
    "\n",
    "            # 3. Initial Mapping & Bridge logic\n",
    "            system_emotion = self.map_to_system_emotion(predicted_label, text)\n",
    "            raw_emotion = system_emotion\n",
    "            \n",
    "            # Special Handling for 'surprise' -> distinguish between happy and stressed\n",
    "            if predicted_label == 'surprise':\n",
    "                positive_kws = {'win', 'gift', 'award', 'happy', 'excited', 'wonderful', 'great'}\n",
    "                negative_kws = {'shock', 'bad', 'exam', 'deadline', 'emergency', 'panic', 'stress'}\n",
    "                \n",
    "                if any(kw in text.lower() for kw in negative_kws):\n",
    "                     raw_emotion = 'stressed'\n",
    "                elif any(kw in text.lower() for kw in positive_kws):\n",
    "                     raw_emotion = 'happy'\n",
    "                else:\n",
    "                     raw_emotion = 'motivated' # Keep existing mapping\n",
    "\n",
    "            # 4. Validation Layer\n",
    "            validated_emotion, validated_confidence = self.validator.validate(\n",
    "                text, raw_emotion, confidence, keywords\n",
    "            )\n",
    "\n",
    "            # 5. Logging\n",
    "            override_flag = \"OVERRIDE\" if raw_emotion != validated_emotion else \"PASS\"\n",
    "            log_msg = f\"{override_flag} | Raw: {raw_emotion} ({confidence:.2f}) -> Validated: {validated_emotion} ({validated_confidence:.2f}) | Keywords: {keywords} | Input: {text[:50]}...\"\n",
    "            validation_logger.info(log_msg)\n",
    "\n",
    "            return validated_emotion, validated_confidence, keywords\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error in predict_emotion: {e}\"\n",
    "            logger.error(error_msg)\n",
    "            error_logger.error(error_msg)\n",
    "            # Fallback\n",
    "            return 'calm', 0.5, []\n",
    "\n",
    "    def map_to_system_emotion(self, bert_label, text):\n",
    "        \"\"\"Bridge NLP labels to system categories with contextual refinement.\"\"\"\n",
    "        # Primary Mapping\n",
    "        mapping = {\n",
    "            'fear': 'anxious',\n",
    "            'anger': 'angry',\n",
    "            'joy': 'happy',\n",
    "            'sadness': 'tired', # mapped in user request\n",
    "            'surprise': 'motivated'\n",
    "        }\n",
    "        \n",
    "        system_emotion = mapping.get(bert_label, 'calm')\n",
    "        \n",
    "        # KEYWORD REFINEMENT: If user mentions 'exam' or 'deadline', force 'stressed'\n",
    "        stress_words = ['exam', 'deadline', 'work', 'project', 'boss', 'overwhelmed']\n",
    "        if any(w in text.lower() for w in stress_words):\n",
    "            return 'stressed'\n",
    "            \n",
    "        return system_emotion\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Quick sanity check\n",
    "    detector = EmotionDetector()\n",
    "    sample_text = \"I am feeling extremely stressed about my upcoming final exams.\"\n",
    "    emotion, conf, keys = detector.predict_emotion(sample_text)\n",
    "    print(f\"Input: {sample_text}\")\n",
    "    print(f\"Emotion: {emotion} (Conf: {conf:.2f})\")\n",
    "    print(f\"Keywords: {keys}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/rl/linucb_recommender.py\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple\n",
    "from threading import Lock\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# --- PRODUCTION UTILITY: REWARD SHAPING ---\n",
    "def calculate_production_reward(watch_time: float, total_duration: float, feedback_type: str = None) -> float:\n",
    "    \"\"\"\n",
    "    Translates user behavior into a human-calibrated scalar reward.\n",
    "    \n",
    "    Args:\n",
    "        watch_time: Seconds watched\n",
    "        total_duration: Total video duration in seconds\n",
    "        feedback_type: Optional explicit signal ('thumbs_up', 'thumbs_down')\n",
    "    \n",
    "    Returns:\n",
    "        Reward value between -1.5 and 1.0\n",
    "    \"\"\"\n",
    "    watch_percent = min(watch_time / max(total_duration, 1), 1.0)\n",
    "    \n",
    "    # 1. Base: Dwell Time (scales -0.4 to 0.6)\n",
    "    reward = (watch_percent * 1.0) - 0.4\n",
    "    \n",
    "    # 2. Explicit Signals (Human-Like Weights)\n",
    "    if feedback_type == \"thumbs_up\":\n",
    "        reward += 0.4  # Max success = 1.0\n",
    "    elif feedback_type == \"thumbs_down\":\n",
    "        reward = -1.5  # Risk Aversion: Strong penalty to stop bad recs immediately\n",
    "        \n",
    "    return max(min(reward, 1.0), -1.5)\n",
    "\n",
    "@dataclass\n",
    "class LinUCBModel:\n",
    "    A: np.ndarray  # Design matrix\n",
    "    b: np.ndarray  # Reward vector\n",
    "    theta: np.ndarray  # Weights\n",
    "    interaction_count: int = 0\n",
    "    lock: Lock = field(default_factory=Lock, repr=False)  # Thread-safe updates\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        if 'lock' in state:\n",
    "            del state['lock']\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "        self.lock = Lock()\n",
    "\n",
    "class LinUCBRecommender:\n",
    "    def __init__(self, context_dim: int = 19, alpha: float = 1.0, lambda_forget: float = 0.99):\n",
    "        self.context_dim = context_dim\n",
    "        self.alpha = alpha\n",
    "        self.lambda_forget = lambda_forget  # Temporal discounting factor\n",
    "        self.models: Dict[str, LinUCBModel] = {}\n",
    "        self.total_interactions = 0\n",
    "        \n",
    "    def _get_key(self, emotion: str, category: str) -> str:\n",
    "        return f\"{emotion}_{category}\"\n",
    "        \n",
    "    def _init_model(self) -> LinUCBModel:\n",
    "        return LinUCBModel(\n",
    "            A=np.identity(self.context_dim),\n",
    "            b=np.zeros((self.context_dim, 1)),\n",
    "            theta=np.zeros((self.context_dim, 1)),\n",
    "            interaction_count=0,\n",
    "            lock=Lock()\n",
    "        )\n",
    "        \n",
    "    def get_or_create_model(self, emotion, category) -> LinUCBModel:\n",
    "        key = self._get_key(emotion, category)\n",
    "        if key not in self.models:\n",
    "            self.models[key] = self._init_model()\n",
    "        return self.models[key]\n",
    "\n",
    "    def build_context_vector(self, emotion, category, video_features, user_context_dict):\n",
    "        \"\"\"Construct the 19-dim context vector.\"\"\"\n",
    "        # Emotion (7)\n",
    "        emotions = ['stressed', 'sad', 'happy', 'anxious', 'tired', 'motivated', 'calm']\n",
    "        emotion_vec = np.zeros(7)\n",
    "        if emotion in emotions:\n",
    "            emotion_vec[emotions.index(emotion)] = 1.0\n",
    "        else:\n",
    "            emotion_vec[6] = 1.0 # Default calm\n",
    "\n",
    "        # Category (4)\n",
    "        categories = ['exercise', 'yoga', 'meditation', 'reading']\n",
    "        cat_vec = np.zeros(4)\n",
    "        if category in categories:\n",
    "            cat_vec[categories.index(category)] = 1.0\n",
    "        else:\n",
    "            cat_vec[1] = 1.0 # Default yoga\n",
    "            \n",
    "        # Video Features (5) - Expected to be normalized\n",
    "        vid_vec = np.array(video_features[:5])\n",
    "        \n",
    "        # User Context (3)\n",
    "        user_vec = np.array([\n",
    "            user_context_dict.get('avg_feedback', 0.0),\n",
    "            min(user_context_dict.get('interaction_count', 0) / 100.0, 1.0), # Normalize cap\n",
    "            user_context_dict.get('success_rate', 0.0)\n",
    "        ])\n",
    "        \n",
    "        context = np.concatenate([emotion_vec, cat_vec, vid_vec, user_vec])\n",
    "        return context.reshape(-1, 1)\n",
    "\n",
    "    def select_video(self, candidates, emotion, category, user_context) -> Tuple[Dict, List[float]]:\n",
    "        model = self.get_or_create_model(emotion, category)\n",
    "        A_inv = np.linalg.inv(model.A)\n",
    "        \n",
    "        ucb_scores = []\n",
    "        best_score = -float('inf')\n",
    "        selected_vid = None\n",
    "        \n",
    "        for vid in candidates:\n",
    "            # Context\n",
    "            ctx = self.build_context_vector(emotion, category, vid['features'], user_context)\n",
    "            \n",
    "            # UCB\n",
    "            mean = (model.theta.T @ ctx).item()\n",
    "            confidence = self.alpha * np.sqrt((ctx.T @ A_inv @ ctx).item())\n",
    "            score = mean + confidence\n",
    "            ucb_scores.append(score)\n",
    "            \n",
    "            # Store context temporarily for update convenience if this vid is chosen\n",
    "            # Note: In real app, we usually recompute or cache by request_id\n",
    "            vid['_temp_context'] = ctx\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                selected_vid = vid\n",
    "                \n",
    "        return selected_vid, ucb_scores\n",
    "\n",
    "    def get_ucb_score(self, emotion, category, context_vector) -> Tuple[float, float]:\n",
    "        \"\"\"Calculate UCB score with numerical stability fixes and thread safety.\"\"\"\n",
    "        model = self.get_or_create_model(emotion, category)\n",
    "        \n",
    "        try:\n",
    "            with model.lock:  # Thread-safe read\n",
    "                # NUMERICAL STABILITY: Use pinv for robust inversion\n",
    "                A_inv = np.linalg.pinv(model.A)\n",
    "                \n",
    "                mean = (model.theta.T @ context_vector).item()\n",
    "                \n",
    "                # Exploration bonus with variance check\n",
    "                var = context_vector.T @ A_inv @ context_vector\n",
    "                uncertainty = self.alpha * np.sqrt(np.maximum(0, var.item()))\n",
    "                \n",
    "            return mean + uncertainty, uncertainty\n",
    "        except np.linalg.LinAlgError:\n",
    "            logger.error(\"Matrix inversion failed in get_ucb_score. Returning zero.\")\n",
    "            return 0.0, self.alpha  # Safe fallback\n",
    "\n",
    "    def update(self, emotion, category, context, reward):\n",
    "        \"\"\"Thread-safe update with temporal discounting (human-like forgetting).\"\"\"\n",
    "        model = self.get_or_create_model(emotion, category)\n",
    "        \n",
    "        with model.lock:  # Thread-safe write\n",
    "            # Apply Temporal Discounting (Human-like 'forgetting')\n",
    "            model.A = (self.lambda_forget * model.A) + (context @ context.T)\n",
    "            model.b = (self.lambda_forget * model.b) + (reward * context)\n",
    "            \n",
    "            # NUMERICAL STABILITY: Use solve instead of direct inverse\n",
    "            try:\n",
    "                model.theta = np.linalg.solve(model.A, model.b)\n",
    "            except np.linalg.LinAlgError:\n",
    "                logger.error(\"Matrix solve failed. Resetting A to identity.\")\n",
    "                model.A = np.identity(self.context_dim)\n",
    "                model.theta = np.zeros((self.context_dim, 1))\n",
    "            \n",
    "            model.interaction_count += 1\n",
    "            self.total_interactions += 1\n",
    "            \n",
    "            # Decay alpha\n",
    "            if self.total_interactions > 100:\n",
    "                self.alpha = max(0.1, self.alpha * 0.999)\n",
    "\n",
    "    def save(self, path='./models/linucb_models.pkl'):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        data = {\n",
    "            'models': self.models,\n",
    "            'total_interactions': self.total_interactions,\n",
    "            'alpha': self.alpha\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "            \n",
    "    def load(self, path='./models/linucb_models.pkl'):\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            self.models = data['models']\n",
    "            self.total_interactions = data['total_interactions']\n",
    "            self.alpha = data['alpha']\n",
    "\n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"Return internal statistics for monitoring.\"\"\"\n",
    "        models_info = {}\n",
    "        for key, model in self.models.items():\n",
    "            models_info[key] = {\n",
    "                'interactions': model.interaction_count,\n",
    "                'weight_norm': np.linalg.norm(model.theta)\n",
    "            }\n",
    "            \n",
    "        return {\n",
    "            'total_interactions': self.total_interactions,\n",
    "            'models_trained': len(self.models),\n",
    "            'current_alpha': self.alpha,\n",
    "            'model_details': models_info\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Core Implementation**\n",
    "\n",
    "**4a. Model Logic:**\n",
    "The core logic resides in `HybridRecommendationSystem`. It acts as the conductor. It fuses the highly personalized score from LinUCB with a **Heuristic Ranker**. \n",
    "-   *Why a heuristic fall-back?* Pure RL can initially be random (extreme exploration). To prevent showing low-quality videos during this phase, we average the RL score with a heuristic score based on the video's engagement ratio. This ensures 'Safety in Exploration'.\n",
    "\n",
    "**4b. Recommendation Pipeline:**\n",
    "1.  **Prediction:** `get_recommendations()` runs the forward pass (Context -> Theta -> Score).\n",
    "2.  **Learning:** `process_feedback()` performs the backward pass. It takes the feedback reward $r$ and updates the matrices: $A \\leftarrow A + xx^T$ and $b \\leftarrow b + rx$.\n",
    "\n",
    "**4c. Code Verification:**\n",
    "The following cells contain the complete source code for the pipeline, designed to run top-to-bottom without errors. We use `%%writefile` to simulate the modular package structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ml/heuristic_ranker.py\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "class HeuristicRanker:\n",
    "    \"\"\"\n",
    "    Simple baseline ranker using weighted combination of\n",
    "    normalized popularity and engagement metrics.\n",
    "    Replaces random stub until LightGBM model is ready.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def score(self, candidates):\n",
    "        \"\"\"\n",
    "        Score a list of candidates based on heuristic logic.\n",
    "        \n",
    "        Args:\n",
    "            candidates: List of dicts, each containing 'features'\n",
    "                        Features expected: [views, engagement, subscribers, duration, recency]\n",
    "                        \n",
    "        Returns:\n",
    "            List of float scores (0.0 to 1.0)\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for vid in candidates:\n",
    "            feats = vid.get('features', [])\n",
    "            if len(feats) < 2:\n",
    "                scores.append(0.5) # Default neutral score\n",
    "                continue\n",
    "\n",
    "            # Heuristic: 0.5 * normalized_views + 0.5 * engagement_ratio\n",
    "            # Assuming feats[0] is log_views (0-10 range typically)\n",
    "            # Assuming feats[1] is engagement_ratio (0-1 range)\n",
    "            \n",
    "            # Normalize log_views roughly to 0-1 (assuming max log_view ~ 15)\n",
    "            # Note: In production, use the FeatureNormalizer for strict bounds.\n",
    "            # Here we just want a rough signal.\n",
    "            \n",
    "            norm_views = min(feats[0] / 15.0, 1.0)\n",
    "            engagement = min(max(feats[1], 0.0), 1.0)\n",
    "            \n",
    "            score = 0.5 * norm_views + 0.5 * engagement\n",
    "            scores.append(score)\n",
    "            \n",
    "        return scores\n",
    "\n",
    "    def get_score(self, vid: dict) -> float:\n",
    "        \"\"\"Calculate score for a single candidate.\"\"\"\n",
    "        feats = vid.get('features', [])\n",
    "        if len(feats) < 2:\n",
    "            return 0.5\n",
    "        norm_views = min(feats[0] / 15.0, 1.0)\n",
    "        engagement = min(max(feats[1], 0.0), 1.0)\n",
    "        return 0.5 * norm_views + 0.5 * engagement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/api/user_context_manager.py\n",
    "class UserContextManager:\n",
    "    \"\"\"\n",
    "    Manages user session data and interaction history in-memory.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # {user_id: {'interactions': int, 'avg_feedback': float, 'success_count': int}}\n",
    "        self.user_store = {}\n",
    "\n",
    "    def get_user_context(self, user_id):\n",
    "        \"\"\"\n",
    "        Retrieve context stats for a user.\n",
    "        Args:\n",
    "            user_id: string identifier\n",
    "        Returns:\n",
    "            dict with context features\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_store:\n",
    "            # Cold user\n",
    "            return {\n",
    "                'avg_feedback': 0.0,\n",
    "                'interaction_count': 0,\n",
    "                'success_rate': 0.0\n",
    "            }\n",
    "        \n",
    "        data = self.user_store[user_id]\n",
    "        total = data['interactions']\n",
    "        success_rate = data['success_count'] / total if total > 0 else 0.0\n",
    "        \n",
    "        return {\n",
    "            'avg_feedback': data['avg_feedback'],\n",
    "            'interaction_count': total,\n",
    "            'success_rate': success_rate\n",
    "        }\n",
    "\n",
    "    def update_user_context(self, user_id, reward):\n",
    "        \"\"\"\n",
    "        Update user stats after feedback.\n",
    "        Reward is assumed -1 to 1.\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_store:\n",
    "            self.user_store[user_id] = {\n",
    "                'interactions': 0,\n",
    "                'avg_feedback': 0.0,\n",
    "                'success_count': 0\n",
    "            }\n",
    "        \n",
    "        data = self.user_store[user_id]\n",
    "        \n",
    "        # Update running average\n",
    "        n = data['interactions']\n",
    "        current_avg = data['avg_feedback']\n",
    "        new_avg = (current_avg * n + reward) / (n + 1)\n",
    "        \n",
    "        data['avg_feedback'] = new_avg\n",
    "        data['interactions'] += 1\n",
    "        \n",
    "        if reward > 0:\n",
    "            data['success_count'] += 1\n",
    "            \n",
    "        self.user_store[user_id] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/api/recommendation_endpoint.py\n",
    "import logging\n",
    "import numpy as np\n",
    "from src.ml.heuristic_ranker import HeuristicRanker\n",
    "from src.rl.linucb_recommender import LinUCBRecommender, calculate_production_reward\n",
    "from src.api.user_context_manager import UserContextManager\n",
    "from src.ml.feature_normalizer import FeatureNormalizer\n",
    "from src.ml.emotion_detector import EmotionDetector\n",
    "from src.api.youtube_service import YouTubeService\n",
    "from src.api.mock_youtube_service import MockYouTubeService\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class HybridRecommendationSystem:\n",
    "    def __init__(self, use_mock_youtube=False):\n",
    "        \"\"\"\n",
    "        Initialize complete recommendation system with real or mock YouTube service.\n",
    "        Automatically checks for YOUTUBE_API_KEY env var.\n",
    "        \"\"\"\n",
    "        import os\n",
    "        api_key = os.environ.get('YOUTUBE_API_KEY')\n",
    "        \n",
    "        # Fallback to mock if explicitly requested OR if no API key present\n",
    "        if use_mock_youtube or not api_key:\n",
    "            self.youtube = MockYouTubeService()\n",
    "            mode = \"Mock (Explicit)\" if use_mock_youtube else \"Mock (Fallback - No API Key)\"\n",
    "            logger.info(f\"Using {mode} YouTubeService\")\n",
    "        else:\n",
    "            self.youtube = YouTubeService()\n",
    "            logger.info(\"Using real YouTubeService\")\n",
    "        \n",
    "        self.emotion_detector = EmotionDetector()\n",
    "        \n",
    "        # ML components\n",
    "        self.feature_normalizer = FeatureNormalizer()\n",
    "        self.linucb = LinUCBRecommender(context_dim=19, alpha=1.0)\n",
    "        self.context_manager = UserContextManager()\n",
    "        self.heuristic_ranker = HeuristicRanker()\n",
    "        \n",
    "        # Load saved models\n",
    "        try:\n",
    "            self.linucb.load('./models/linucb_models.pkl')\n",
    "            logger.info(\"Loaded existing LinUCB models\")\n",
    "        except FileNotFoundError:\n",
    "            logger.info(\"Starting with fresh LinUCB models\")\n",
    "\n",
    "    def get_recommendations(self, \n",
    "                           user_input: str = \"\",\n",
    "                           user_id: str = \"seeker_01\",\n",
    "                           emotion: str = None,\n",
    "                           candidates: list = None,\n",
    "                           just_ate: bool = False,\n",
    "                           hour: int = None,\n",
    "                           max_results: int = 12, top_n: int = 4) -> dict:\n",
    "        \"\"\"\n",
    "        Orchestrated pipeline with Bio-Context: NLP Detector -> Bio-Search -> Hybrid scoring.\n",
    "        Allows manual emotion/candidate injection for testing/advanced flows.\n",
    "        \"\"\"\n",
    "        # 1. Biological Context (Cloud-ready: Use injected hour or fallback to system)\n",
    "        from datetime import datetime\n",
    "        if hour is None:\n",
    "            hour = datetime.now().hour\n",
    "        if 5 <= hour < 11:\n",
    "            phase = \"morning\"\n",
    "        elif 11 <= hour < 16:\n",
    "            phase = \"midday\"\n",
    "        elif 16 <= hour < 19:\n",
    "            phase = \"afternoon\"\n",
    "        else:\n",
    "            phase = \"evening\"\n",
    "            \n",
    "        # 2. Detect Emotion & Keywords (Unified NLP Bridge)\n",
    "        confidence = 1.0\n",
    "        keywords = []\n",
    "        \n",
    "        if emotion:\n",
    "             system_emotion = emotion\n",
    "             logger.info(f\"Using provided emotion: {system_emotion}\")\n",
    "        else:\n",
    "            system_emotion, confidence, keywords = self.emotion_detector.predict_emotion(user_input)\n",
    "            \n",
    "        logger.info(f\"NLP: {system_emotion} | Phase: {phase} | Food Safety: {just_ate}\")\n",
    "        \n",
    "        # 3. Search YouTube (Expanded with Keywords & Bio-Context)\n",
    "        if candidates is not None:\n",
    "             logger.info(f\"Using {len(candidates)} provided candidates\")\n",
    "        else:\n",
    "            query = self.youtube.build_bio_query(system_emotion, phase, just_ate, keywords)\n",
    "            candidates = self.youtube.search_and_enrich(query, max_results=max_results)\n",
    "        \n",
    "        if not candidates:\n",
    "            return {\"emotion\": system_emotion, \"phase\": phase, \"recommendations\": []}\n",
    "\n",
    "        # 4. Scoring & Normalization\n",
    "        user_ctx = self.context_manager.get_user_context(user_id)\n",
    "        scored_vids = []\n",
    "        \n",
    "        # Prepare candidates\n",
    "        processed_candidates = self._prepare_candidates(candidates)\n",
    "        \n",
    "        for vid in processed_candidates:\n",
    "            # RL Context Vector (d=19, stable)\n",
    "            ctx_vec = self.linucb.build_context_vector(system_emotion, 'yoga', vid['features'], user_ctx)\n",
    "            \n",
    "            # Hybrid Calculation\n",
    "            rl_score, _ = self.linucb.get_ucb_score(system_emotion, 'yoga', ctx_vec)\n",
    "            h_score = self.heuristic_ranker.get_score(vid)\n",
    "            \n",
    "            # Dynamic weighting: max 0.7 RL influence\n",
    "            w = min(user_ctx.get('interaction_count', 0) / 20.0, 0.7)\n",
    "            final_raw_score = (w * rl_score) + ((1 - w) * h_score) + vid.get('demo_boost', 0.0)\n",
    "            \n",
    "            # Sigmoid normalization\n",
    "            match_percent = 1 / (1 + np.exp(-final_raw_score))\n",
    "            \n",
    "            vid.update({\n",
    "                'match_score': round(float(match_percent * 100), 1),\n",
    "                'score': float(final_raw_score),\n",
    "                '_context': ctx_vec,\n",
    "                'heuristic_score': float(h_score),\n",
    "                'linucb_score': float(rl_score)\n",
    "            })\n",
    "            scored_vids.append(vid)\n",
    "\n",
    "        return {\n",
    "            \"emotion\": system_emotion,\n",
    "            \"confidence\": confidence,\n",
    "            \"phase\": phase,\n",
    "            \"just_ate\": just_ate,\n",
    "            \"keywords\": keywords,\n",
    "            \"recommendations\": sorted(scored_vids, key=lambda x: x['score'], reverse=True)[:top_n],\n",
    "            \"metadata\": {\n",
    "                \"w_rl\": w,\n",
    "                \"user_id\": user_id,\n",
    "                \"total_candidates\": len(candidates)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _prepare_candidates(self, videos: list) -> list:\n",
    "        \"\"\"\n",
    "        Transform YouTube video data into candidate format with normalized features.\n",
    "        \"\"\"\n",
    "        prepared = []\n",
    "        \n",
    "        for video in videos:\n",
    "            try:\n",
    "                # Extract raw features\n",
    "                views = video.get('views', 0)\n",
    "                likes = video.get('likes', 0)\n",
    "                subscribers = video.get('channel_subscribers', 0)\n",
    "                duration = video.get('duration_minutes', 15.0)\n",
    "                days_ago = video.get('published_days_ago', 180)\n",
    "                \n",
    "                # Compute features\n",
    "                log_views = np.log1p(views)\n",
    "                engagement = likes / max(views, 1)\n",
    "                log_subs = np.log1p(subscribers)\n",
    "                duration_norm = min(duration / 30.0, 1.0)  # Cap at 1.0\n",
    "                recency = 1.0 / (days_ago + 1)\n",
    "                \n",
    "                # Create raw feature vector\n",
    "                raw_features = np.array([\n",
    "                    log_views,\n",
    "                    engagement,\n",
    "                    log_subs,\n",
    "                    duration_norm,\n",
    "                    recency\n",
    "                ])\n",
    "                \n",
    "                # Normalize (or fit if first time)\n",
    "                if not self.feature_normalizer.is_fitted:\n",
    "                    # Collect all features first\n",
    "                    all_raw = []\n",
    "                    for v in videos:\n",
    "                        try:\n",
    "                            vw = v.get('views', 0)\n",
    "                            lk = v.get('likes', 0)\n",
    "                            sb = v.get('channel_subscribers', 0)\n",
    "                            dr = v.get('duration_minutes', 15.0)\n",
    "                            da = v.get('published_days_ago', 180)\n",
    "                            \n",
    "                            all_raw.append([\n",
    "                                np.log1p(vw),\n",
    "                                lk / max(vw, 1),\n",
    "                                np.log1p(sb),\n",
    "                                min(dr / 30.0, 1.0),\n",
    "                                1.0 / (da + 1)\n",
    "                            ])\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    if all_raw:\n",
    "                        self.feature_normalizer.fit(np.array(all_raw))\n",
    "                        logger.info(\"Fitted feature normalizer on batch\")\n",
    "                \n",
    "                # Transform features\n",
    "                normalized_features = self.feature_normalizer.transform(raw_features)\n",
    "                \n",
    "                # Add to video dict\n",
    "                video['features'] = normalized_features\n",
    "                prepared.append(video)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to process video {video.get('video_id', 'unknown')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Prepared {len(prepared)} valid candidates\")\n",
    "        return prepared\n",
    "\n",
    "    def _get_linucb_weight(self):\n",
    "        \"\"\"Determine weighting for hybrid ranking based on system maturity.\"\"\"\n",
    "        n_interactions = self.linucb.total_interactions\n",
    "        if n_interactions < 50:\n",
    "            return 0.2\n",
    "        elif n_interactions < 200:\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0.8\n",
    "            \n",
    "    def _hybrid_score_and_select(self, candidates, emotion, category, user_ctx, top_n):\n",
    "        \"\"\"Score candidates using Heuristic and LinUCB\"\"\"\n",
    "        # 1. Score Heuristically (Quality)\n",
    "        h_scores = self.heuristic_ranker.score(candidates)\n",
    "        \n",
    "        # 2. Score RL (Personalization)\n",
    "        rl_scores = []\n",
    "        for cand in candidates:\n",
    "            ctx_vector = self.linucb.build_context_vector(emotion, category, cand['features'], user_ctx)\n",
    "            score, _ = self.linucb.get_ucb_score(emotion, category, ctx_vector)\n",
    "            rl_scores.append(score)\n",
    "            \n",
    "        # 3. Hybrid Weighing\n",
    "        w_rl = self._get_linucb_weight()\n",
    "        \n",
    "        final_scores = []\n",
    "        for i, (h, rl) in enumerate(zip(h_scores, rl_scores)):\n",
    "            raw_score = w_rl * rl + (1 - w_rl) * h\n",
    "            \n",
    "            # Implementation: Sigmoid function to normalize 0-100%\n",
    "            # Center it around typical score values if needed, otherwise standard sigmoid\n",
    "            sigmoid_score = 1 / (1 + np.exp(-raw_score))\n",
    "            match_pct = int(sigmoid_score * 100)\n",
    "            \n",
    "            final_scores.append(raw_score)\n",
    "            candidates[i]['score'] = raw_score\n",
    "            candidates[i]['match_score'] = match_pct\n",
    "            candidates[i]['heuristic_score'] = h\n",
    "            candidates[i]['linucb_score'] = rl\n",
    "            candidates[i]['_context'] = user_ctx # Keep context for feedback\n",
    "            \n",
    "        # 4. Sort and Return\n",
    "        ranked_indices = np.argsort(final_scores)[::-1]\n",
    "        top_recs = [candidates[i] for i in ranked_indices[:top_n]]\n",
    "        \n",
    "        return top_recs\n",
    "\n",
    "    def process_feedback(self, user_id, emotion, category, video_id, feedback, \n",
    "                         context=None, video_features=None, \n",
    "                         watch_time=None, total_duration=None):\n",
    "        \"\"\"\n",
    "        Process user feedback with optional watch-time-based reward shaping.\n",
    "        \n",
    "        Args:\n",
    "            watch_time: Seconds watched (optional, enables nuanced reward)\n",
    "            total_duration: Total video duration in seconds\n",
    "        \"\"\"\n",
    "        # Calculate Reward: Use production reward shaping if watch_time available\n",
    "        if watch_time is not None and total_duration is not None:\n",
    "            reward = calculate_production_reward(watch_time, total_duration, feedback)\n",
    "        else:\n",
    "            # Fallback: Simple mapping for explicit signals only\n",
    "            if feedback == 'thumbs_up':\n",
    "                reward = 1.0\n",
    "            elif feedback == 'thumbs_down':\n",
    "                reward = -1.0\n",
    "            else:\n",
    "                return {'status': 'ignored'}\n",
    "            \n",
    "        self.context_manager.update_user_context(user_id, reward)\n",
    "        \n",
    "        # Update LinUCB if features available\n",
    "        if video_features is not None and context is not None:\n",
    "             if isinstance(context, np.ndarray):\n",
    "                 ctx_vector = context\n",
    "             else:\n",
    "                 ctx_vector = self.linucb.build_context_vector(emotion, category, video_features, context)\n",
    "             self.linucb.update(emotion, category, ctx_vector, reward)\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'reward': reward,\n",
    "            'total_interactions': self.linucb.total_interactions,\n",
    "            'linucb_weight': self._get_linucb_weight()\n",
    "        }\n",
    "\n",
    "    def detect_emotion_and_context(self, text):\n",
    "        return self.emotion_detector.predict_emotion(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Evaluation & Analysis**\n",
    "\n",
    "**5a. Metrics Used:**\n",
    "-   **Confidence Score:** The probability from the softmax output of the DistilBERT model. High confidence (>0.85) means the system strongly recognized the emotion.\n",
    "-   **Production Reward:** We perform **Reward Shaping**. Instead of a binary 'like/dislike', we define a continuous reward signal: $R = (WatchTime / Duration) + (0.5 \\times ExplicitLike)$. This granular metric helps the RL agent learn faster.\n",
    "\n",
    "**5b. Sample Output & Analysis:**\n",
    "The simulation below demonstrates a user expressing 'Work Stress'.\n",
    "-   **Detected:** 'Fear/Anxiety' (Correctly mapped from stress keywords).\n",
    "-   **Action:** System recommends a 10-minute 'Yoga for Anxiety' video.\n",
    "-   **Result:** User gives a 'Thumbs Up'. The system prints the updated Total Interactions, proving the learning loop is closed.\n",
    "\n",
    "**5c. Performance Analysis:**\n",
    "The hybrid model demonstrates robustness. Even with no prior history (Interaction Count = 0), the Heuristic Ranker ensures the top recommendation is a high-quality video (high engagement ratio), solving the 'Cold Start' quality issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current directory to path so imports work\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "from src.api.recommendation_endpoint import HybridRecommendationSystem\n",
    "\n",
    "print(\"Initializing Hybrid System (With Mock Data for Reproducibility)...\\n\")\n",
    "system = HybridRecommendationSystem(use_mock_youtube=True)\n",
    "\n",
    "user_query = \"I'm feeling super stressed with work\"\n",
    "print(f\"User Input: {user_query}\")\n",
    "\n",
    "# 1. Get Recommendations\n",
    "recs_data = system.get_recommendations(user_query, \"simulation_user\")\n",
    "recs = recs_data['recommendations']\n",
    "\n",
    "if recs:\n",
    "    top = recs[0]\n",
    "    print(f\"Detected Emotion: {recs_data['emotion']}\")\n",
    "    print(f\"Recommendation: '{top['title']}'\")\n",
    "    print(f\"Reasoning: Match Score {top['match_score']}% (Heuristic + RL)\")\n",
    "    \n",
    "    # 2. Feedback Loop Simulation\n",
    "    print(\"\\n--- Simulating User Feedback ---\")\n",
    "    print(\"User watched 5 minutes (50%) and Liked the video.\")\n",
    "    res = system.process_feedback('simulation_user', recs_data['emotion'], 'yoga', top['video_id'], 'thumbs_up', \n",
    "                            context=top.get('_context'), video_features=top.get('features'),\n",
    "                            watch_time=300, total_duration=600)\n",
    "    print(f\"System Updated: Reward = {res['reward']:.2f} | Interactions Logged = {res['total_interactions']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Ethical Considerations & Responsible AI**\n",
    "\n",
    "**6a. Bias and Fairness:**\n",
    "Algorithmic bias is a risk in all RS (Recommendation Systems). If the training data (YouTube views) is biased toward certain demographics, the AI will mirror that. We mitigate this by:\n",
    "1.  **Diversity Re-ranking:** Ensuring a mix of channels in the candidate pool.\n",
    "2.  **Explicit Exploration:** The $\\alpha$ term in LinUCB forces the model to try less popular videos, giving exposure to diverse creators.\n",
    "\n",
    "**6b. Dataset Limitations:**\n",
    "We rely on metadata (titles/tags). Clickbait titles might fool the NLP. Future work involves video content analysis (computer vision) to verify if a video is *actually* yoga.\n",
    "\n",
    "**6c. Responsible Use (Crisis Intervention):**\n",
    "This is a wellness tool, not a medical one. We implemented a **Safety Layer** in `EmotionValidator`. If high-risk keywords (e.g., self-harm) are detected, the system overrides recommendations and provides helpline numbers. This is a non-negotiable ethical guardrail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Conclusion & Future Scope**\n",
    "\n",
    "**7a. Summary of Results:**\n",
    "We have successfully developed **Wellness Sanctuary**, a production-ready application that bridges the gap between raw content and human emotional needs. By integrating state-of-the-art NLP with Bayesian Reinforcement Learning, we created a system that is not only accurate but *adaptive*, learning from every user interaction to become more personalized over time.\n",
    "\n",
    "**7b. Future Scope:**\n",
    "-   **Multi-modal Inputs:** Incorporating voice pitch analysis and facial expression (via webcam) to detect stress more accurately.\n",
    "-   **Wearable Integration:** Start recommendations automatically when Apple Health/Fitbit detects a high heart rate (HRV).\n",
    "-   **LLM Chatbot:** Replacing the static search with a conversational therapist agent (Llama-3) for pre-screening.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Appendix: Frontend (Streamlit)**\n",
    "The code below generates the `streamlit_app.py` file used for the web interface. This file handles the UI logic, session state, and user interaction components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate placeholder asset for the app to work\n",
    "from PIL import Image, ImageDraw\n",
    "try:\n",
    "    img = Image.new('RGB', (400, 300), color = '#4A675A')\n",
    "    d = ImageDraw.Draw(img)\n",
    "    d.text((10,10), \"Sanctuary Lock\", fill=(255,255,255))\n",
    "    os.makedirs('assets', exist_ok=True)\n",
    "    img.save('assets/lock_screen.png')\n",
    "except ImportError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile streamlit_app.py\n",
    "\"\"\"\n",
    "Wellness Sanctuary - Premium Wellness Recommendation System\n",
    "A minimal, elegant interface for soul-nourishing content.\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import uuid\n",
    "import sys\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))\n",
    "\n",
    "from api.recommendation_endpoint import HybridRecommendationSystem\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# CONFIGURATION & THEME\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Wellness Sanctuary\",\n",
    "    page_icon=\"\ud83c\udf3f\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"collapsed\"\n",
    ")\n",
    "\n",
    "# Premium Sanctuary Styles\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    /* Typography Imports */\n",
    "    @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,700;1,400&family=Inter:wght@300;400;500;600&display=swap');\n",
    "    \n",
    "    /* Global Overrides */\n",
    "    .stApp {\n",
    "        background-color: #FFFFFF;\n",
    "        color: #2F3437;\n",
    "    }\n",
    "    \n",
    "    /* Center Layout (1000px Max) */\n",
    "    .main .block-container {\n",
    "        max-width: 1000px;\n",
    "        padding-top: 3rem;\n",
    "        margin: auto;\n",
    "    }\n",
    "\n",
    "    /* Headings & Body */\n",
    "    h1, h2, h3, .playfair {\n",
    "        font-family: 'Playfair Display', serif !important;\n",
    "        color: #1A1C1D !important;\n",
    "        font-weight: 700 !important;\n",
    "    }\n",
    "    \n",
    "    p, span, div, label, .inter {\n",
    "        font-family: 'Inter', sans-serif !important;\n",
    "        color: #4A4E51 !important;\n",
    "    }\n",
    "\n",
    "    /* Posture Images Gallery */\n",
    "    .yoga-image-container {\n",
    "        display: flex;\n",
    "        flex-wrap: wrap;\n",
    "        justify-content: center;\n",
    "        gap: 2rem;\n",
    "        margin-bottom: 3rem;\n",
    "        position: relative; /* Added for absolute positioning of title */\n",
    "    }\n",
    "    .yoga-image {\n",
    "        width: 280px;\n",
    "        border-radius: 16px;\n",
    "        opacity: 0.9;\n",
    "        transition: transform 0.4s ease, opacity 0.3s ease;\n",
    "        box-shadow: 0 4px 20px rgba(0,0,0,0.03);\n",
    "    }\n",
    "    .yoga-image:hover {\n",
    "        opacity: 1;\n",
    "        transform: translateY(-5px);\n",
    "    }\n",
    "\n",
    "    /* Input Styling - Minimalist & Rounded */\n",
    "    .stTextInput > div > div > input {\n",
    "        border-radius: 12px !important;\n",
    "        border: 1px solid #E1E4E6 !important;\n",
    "        padding: 0.8rem 1.2rem !important;\n",
    "        background-color: #F9FAFB !important;\n",
    "        font-size: 1rem !important;\n",
    "        color: #1A1C1D !important;\n",
    "    }\n",
    "    \n",
    "    .stTextInput > div > div > input:focus {\n",
    "        border-color: #4A675A !important;\n",
    "        background-color: #FFFFFF !important;\n",
    "    }\n",
    "    \n",
    "    /* Hide Default Red Borders on Error/Focus */\n",
    "    [data-baseweb=\"input\"] {\n",
    "        border-color: transparent !important;\n",
    "    }\n",
    "\n",
    "    /* Button Styling */\n",
    "    .stButton > button {\n",
    "        background-color: #4A675A !important;\n",
    "        color: #FFFFFF !important;\n",
    "        border-radius: 30px !important;\n",
    "        padding: 0.75rem 2.5rem !important;\n",
    "        font-weight: 600 !important;\n",
    "        border: none !important;\n",
    "        transition: all 0.3s ease !important;\n",
    "        letter-spacing: 0.05em !important;\n",
    "        text-transform: uppercase !important;\n",
    "        box-shadow: 0 4px 6px rgba(74, 103, 90, 0.2) !important;\n",
    "    }\n",
    "    \n",
    "    .stButton > button:hover {\n",
    "        background-color: #3D554A !important;\n",
    "        transform: translateY(-2px);\n",
    "        box-shadow: 0 10px 15px -3px rgba(74, 103, 90, 0.3) !important;\n",
    "        color: #FFFFFF !important;\n",
    "    }\n",
    "\n",
    "    /* Video Cards with Refined Hover Lift (User Request: -5px) */\n",
    "    /* Card Entrance Animation */\n",
    "    @keyframes fadeIn {\n",
    "        from { opacity: 0; transform: translateY(20px); }\n",
    "        to { opacity: 1; transform: translateY(0); }\n",
    "    }\n",
    "    \n",
    "    .video-card {\n",
    "        background: #FFFFFF;\n",
    "        border-radius: 24px;\n",
    "        overflow: hidden;\n",
    "        border: 1px solid rgba(0,0,0,0.03);\n",
    "        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.04);\n",
    "        transition: all 0.4s cubic-bezier(0.165, 0.84, 0.44, 1);\n",
    "        margin-bottom: 2rem;\n",
    "        height: 100%;\n",
    "        position: relative;\n",
    "        animation: fadeIn 0.8s ease-out forwards;\n",
    "    }\n",
    "    \n",
    "    .video-card:hover {\n",
    "        transform: translateY(-5px);\n",
    "        box-shadow: 0 20px 40px rgba(74, 103, 90, 0.1) !important;\n",
    "        border: 1px solid #7B9E89;\n",
    "    }\n",
    "    \n",
    "    .card-thumb {\n",
    "        width: 100%;\n",
    "        aspect-ratio: 16 / 9;\n",
    "        object-fit: cover;\n",
    "    }\n",
    "    \n",
    "    .card-content {\n",
    "        padding: 1.5rem;\n",
    "    }\n",
    "    \n",
    "    .match-pill {\n",
    "        display: inline-block;\n",
    "        background-color: #E7F2EC;\n",
    "        color: #4A675A;\n",
    "        padding: 0.2rem 0.8rem;\n",
    "        border-radius: 8px;\n",
    "        font-size: 0.7rem;\n",
    "        font-weight: 700;\n",
    "        letter-spacing: 0.05em;\n",
    "        margin-bottom: 0.75rem;\n",
    "    }\n",
    "    \n",
    "    .video-title {\n",
    "        font-size: 1.3rem;\n",
    "        font-family: 'Playfair Display', serif !important;\n",
    "        line-height: 1.3;\n",
    "        margin-bottom: 0.5rem;\n",
    "        color: #1A1C1D !important;\n",
    "    }\n",
    "\n",
    "    /* Breathing Bubble Animation (Enhanced) */\n",
    "    .breathing-container {\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "        align-items: center;\n",
    "        justify-content: center;\n",
    "        padding: 6rem 0;\n",
    "    }\n",
    "\n",
    "    .breathing-circle {\n",
    "        width: 120px;\n",
    "        height: 120px;\n",
    "        background: radial-gradient(circle, rgba(255,140,0,0.4) 0%, rgba(0,191,255,0.2) 50%, rgba(255,255,255,0) 70%);\n",
    "        border: 1px solid rgba(255,140,0,0.1);\n",
    "        border-radius: 50%;\n",
    "        animation: breathe 5s ease-in-out infinite;\n",
    "    }\n",
    "\n",
    "    @keyframes breathe {\n",
    "        0%, 100% { transform: scale(0.8); opacity: 0.3; background: radial-gradient(circle, rgba(255,140,0,0.4) 0%, rgba(0,191,255,0.2) 70%); }\n",
    "        50% { transform: scale(1.6); opacity: 0.8; background: radial-gradient(circle, rgba(0,191,255,0.4) 0%, rgba(255,140,0,0.2) 70%); }\n",
    "    }\n",
    "\n",
    "    .breathing-text {\n",
    "        margin-top: 3rem;\n",
    "        font-family: 'Playfair Display', serif;\n",
    "        font-style: italic;\n",
    "        color: #4A675A;\n",
    "        font-size: 1.4rem;\n",
    "        letter-spacing: 0.02em;\n",
    "    }\n",
    "\n",
    "    /* Hide Streamlit Elements */\n",
    "    #MainMenu {visibility: hidden;}\n",
    "    footer {visibility: hidden;}\n",
    "    [data-testid=\"stHeader\"] {display: none;}\n",
    "    .stDeployButton {display:none;}\n",
    "    \n",
    "    /* Expander Styling - Floating Effect */\n",
    "    .stExpander {\n",
    "        border: none !important;\n",
    "        background: #F9FAFB !important;\n",
    "        border-radius: 12px !important;\n",
    "        margin-top: 1rem !important;\n",
    "        box-shadow: 0 2px 10px rgba(0,0,0,0.02) !important;\n",
    "    }\n",
    "\n",
    "    /* Feedback Buttons */\n",
    "    .feedback-container {\n",
    "        display: flex;\n",
    "        justify-content: flex-end;\n",
    "        gap: 1rem;\n",
    "        padding: 0.5rem 0;\n",
    "    }\n",
    "    \n",
    "    .feedback-btn {\n",
    "        background: none !important;\n",
    "        border: 1px solid #E1E4E6 !important;\n",
    "        border-radius: 50% !important;\n",
    "        width: 40px !important;\n",
    "        height: 40px !important;\n",
    "        display: flex !important;\n",
    "        align-items: center !important;\n",
    "        justify-content: center !important;\n",
    "        cursor: pointer !important;\n",
    "        transition: all 0.3s ease !important;\n",
    "        font-size: 1.2rem !important;\n",
    "        padding: 0 !important;\n",
    "    }\n",
    "\n",
    "    .feedback-btn:hover {\n",
    "        background-color: #F0F2F0 !important;\n",
    "        border-color: #4A675A !important;\n",
    "        transform: scale(1.1);\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# SESSION STATE & SYSTEM\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "if 'user_id' not in st.session_state:\n",
    "    st.session_state.user_id = f\"seeker_{uuid.uuid4().hex[:6]}\"\n",
    "if 'results' not in st.session_state:\n",
    "    st.session_state.results = None\n",
    "if 'last_mood' not in st.session_state:\n",
    "    st.session_state.last_mood = \"\"\n",
    "if 'user_name' not in st.session_state:\n",
    "    st.session_state.user_name = None\n",
    "if 'current_emotion' not in st.session_state:\n",
    "    st.session_state.current_emotion = \"neutral\"\n",
    "if 'authenticated' not in st.session_state:\n",
    "    st.session_state.authenticated = False\n",
    "\n",
    "def check_password():\n",
    "    \"\"\"Returns `True` if the user had the correct password.\"\"\"\n",
    "\n",
    "    def password_entered():\n",
    "        \"\"\"Checks whether a password entered by the user is correct.\"\"\"\n",
    "        # The password for development is 'wellness2026'\n",
    "        # Hashed value of 'wellness2026' using SHA-256\n",
    "        EXPECTED_HASH = \"a4559662e367676980b4e7bea677a03ab55de20bb9cd072a4b52f80baccb7f6c\"\n",
    "        \n",
    "        entered_password = st.session_state[\"password\"]\n",
    "        hashed_entered = hashlib.sha256(entered_password.encode()).hexdigest()\n",
    "        \n",
    "        if hashed_entered == EXPECTED_HASH:\n",
    "            st.session_state[\"authenticated\"] = True\n",
    "            del st.session_state[\"password\"]  # don't store password\n",
    "        else:\n",
    "            st.session_state[\"authenticated\"] = False\n",
    "            st.error(\"\ud83d\ude15 Sanctuary access denied. Please check your credentials.\")\n",
    "\n",
    "    if not st.session_state[\"authenticated\"]:\n",
    "        # First-time user: Enter password\n",
    "        st.markdown('<div style=\"height: 10vh;\"></div>', unsafe_allow_html=True)\n",
    "        \n",
    "        # Lock Screen Image\n",
    "        col_lock_l, col_lock_c, col_lock_r = st.columns([1, 1, 1])\n",
    "        with col_lock_c:\n",
    "            st.image(\"assets/lock_screen.png\", use_container_width=True)\n",
    "            \n",
    "        st.markdown('<h1 style=\"text-align: center; color: #4A675A;\">Sanctuary Lock</h1>', unsafe_allow_html=True)\n",
    "        \n",
    "        col_l, col_c, col_r = st.columns([1, 1, 1])\n",
    "        with col_c:\n",
    "            st.text_input(\n",
    "                \"Password\", type=\"password\", on_change=password_entered, key=\"password\",\n",
    "                placeholder=\"Enter key to unlock...\"\n",
    "            )\n",
    "            st.markdown('<p style=\"font-size: 0.7rem; text-align: center; color: #6D7275;\">Default Key: <code>wellness2026</code></p>', unsafe_allow_html=True)\n",
    "        return False\n",
    "    else:\n",
    "        # Password correct: show the \"Log Out\" button in the sidebar\n",
    "        with st.sidebar:\n",
    "            if st.button(\"Secure Logout\"):\n",
    "                st.session_state[\"authenticated\"] = False\n",
    "                st.rerun()\n",
    "        return True\n",
    "\n",
    "@st.cache_resource\n",
    "def load_sanctuary_controller():\n",
    "    return HybridRecommendationSystem()\n",
    "\n",
    "system = load_sanctuary_controller()\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# MAIN UI\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "def main():\n",
    "    # 0. Security Gate\n",
    "    if not check_password():\n",
    "        return\n",
    "\n",
    "    # Dynamic Sanctuary Greeting\n",
    "    from datetime import datetime\n",
    "    hour = datetime.now().hour\n",
    "    if 5 <= hour < 12:\n",
    "        greeting = \"Good Morning\"\n",
    "    elif 12 <= hour < 17:\n",
    "        greeting = \"Good Afternoon\"\n",
    "    else:\n",
    "        greeting = \"Good Evening\"\n",
    "\n",
    "    # Name Entry State\n",
    "    if not st.session_state.user_name:\n",
    "        st.markdown('<div style=\"height: 10vh;\"></div>', unsafe_allow_html=True)\n",
    "        st.markdown('<h1 style=\"text-align: center; font-size: 3rem; margin-bottom: 2rem;\">Welcome to the Sanctuary.</h1>', unsafe_allow_html=True)\n",
    "        col_name_l, col_name_c, col_name_r = st.columns([1, 2, 1])\n",
    "        with col_name_c:\n",
    "            name_input = st.text_input(\"Tell us, what is your name?\", placeholder=\"Your name...\", key=\"temp_name\")\n",
    "            if st.button(\"Begin Your Journey\", use_container_width=True):\n",
    "                if name_input:\n",
    "                    st.session_state.user_name = name_input\n",
    "                    st.rerun()\n",
    "        return\n",
    "\n",
    "    # Energy Flow Animation Styling\n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .energy-flow {\n",
    "            position: relative;\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        .energy-flow::after {\n",
    "            content: \"\";\n",
    "            position: absolute;\n",
    "            top: 0; left: 0; width: 100%; height: 100%;\n",
    "            background: linear-gradient(180deg, \n",
    "                rgba(255, 140, 0, 0) 0%, \n",
    "                rgba(255, 140, 0, 0.15) 30%, \n",
    "                rgba(0, 191, 255, 0.15) 70%, \n",
    "                rgba(0, 191, 255, 0) 100%);\n",
    "            animation: flowDown 4s ease-in-out infinite;\n",
    "            pointer-events: none;\n",
    "            mix-blend-mode: soft-light;\n",
    "        }\n",
    "        @keyframes flowDown {\n",
    "            0% { transform: translateY(-100%); }\n",
    "            100% { transform: translateY(100%); }\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Yoga Postures integration\n",
    "    import base64\n",
    "    def get_image_base64(path):\n",
    "        try:\n",
    "            with open(path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode()\n",
    "        except: return \"\"\n",
    "\n",
    "    posters = [\n",
    "        os.path.join(\"assets\", \"yoga_posture_1.png\"),\n",
    "        os.path.join(\"assets\", \"yoga_posture_2.png\"),\n",
    "        os.path.join(\"assets\", \"surya_namaskar.png\"),\n",
    "        os.path.join(\"assets\", \"warrior_pose.png\")\n",
    "    ]\n",
    "    \n",
    "    poster_html = \"\"\n",
    "    for p in posters:\n",
    "        b64 = get_image_base64(p)\n",
    "        if b64:\n",
    "            poster_html += f'<div class=\"energy-flow\" style=\"border-radius: 16px;\"><img src=\"data:image/png;base64,{b64}\" class=\"yoga-image\"></div>'\n",
    "\n",
    "       # Welcome Home title above the container\n",
    "    st.markdown('<h2 style=\"text-align: left; font-weight: 700; font-size: 2.5rem; color: #4A675A; font-family: \\'Playfair Display\\', serif; margin-bottom: 1rem;\">Welcome Home</h2>', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(f'''\n",
    "        <div class=\"yoga-image-container\">\n",
    "            {poster_html}\n",
    "        </div>\n",
    "    ''', unsafe_allow_html=True)\n",
    "\n",
    "    # Hero Section\n",
    "    st.markdown(f'<div style=\"text-align: center; margin-bottom: 2rem;\">', unsafe_allow_html=True)\n",
    "    st.markdown(f'<p style=\"color: #4A675A; font-weight: 500; letter-spacing: 0.1em; text-transform: uppercase; font-size: 0.8rem; margin-bottom: 1rem;\">{greeting}, {st.session_state.user_name}</p>', unsafe_allow_html=True)\n",
    "    st.markdown('<h1 style=\"font-size: 4rem; margin-bottom: 1.5rem;\">Peace begins here.</h1>', unsafe_allow_html=True)\n",
    "    st.markdown('<p style=\"font-family: \\'Playfair Display\\', serif; font-size: 1.3rem; color: #6D7275; margin: 0 auto 2rem auto;\">Describe how you feel, and we will curate a practice to ground your soul.</p>', unsafe_allow_html=True)\n",
    "    st.markdown('<p style=\"font-family: \\'Inter\\', sans-serif; font-style: italic; color: #4A675A; font-size: 1.1rem; margin-bottom: 3rem; background: #F9FAFB; padding: 2rem; border-radius: 16px;\">\"You cannot pour from an empty cup. This moment is you refilling yours.\" \u2728</p>', unsafe_allow_html=True)\n",
    "    st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    # Reset Logic: Clear results if biometric context changes\n",
    "    def clear_sanctuary():\n",
    "        st.session_state.results = None\n",
    "        st.session_state.last_query_id = \"\"\n",
    "\n",
    "    # Bio-Context Inputs\n",
    "    col_input, col_bio = st.columns([2, 1])\n",
    "    with col_input:\n",
    "        user_mood = st.text_input(\n",
    "            \"How is your soul today?\",\n",
    "            placeholder=\"e.g., I feel stressed and need to breathe\",\n",
    "            label_visibility=\"collapsed\"\n",
    "        )\n",
    "    with col_bio:\n",
    "        just_ate = st.checkbox(\"I just ate \ud83c\udf72\", on_change=clear_sanctuary)\n",
    "    \n",
    "    col_btn_left, col_btn_center, col_btn_right = st.columns([1, 1, 1])\n",
    "    with col_btn_center:\n",
    "        find_btn = st.button(\"Enter the Sanctuary\", use_container_width=True)\n",
    "\n",
    "    # Logic: Stateful Search \"Lock\"\n",
    "    if find_btn and user_mood:\n",
    "        # Only search if context changed or results are empty\n",
    "        query_id = f\"{user_mood}_{just_ate}\"\n",
    "        if \"results\" not in st.session_state or st.session_state.get('last_query_id') != query_id:\n",
    "            # Show Breathing Bubble Loader\n",
    "            with st.empty():\n",
    "                st.markdown(\"\"\"\n",
    "                    <div class=\"breathing-container\">\n",
    "                        <div class=\"breathing-circle\"></div>\n",
    "                        <div class=\"breathing-text\">\ud83c\udf3f Designing your sanctuary...</div>\n",
    "                    </div>\n",
    "                \"\"\", unsafe_allow_html=True)\n",
    "                \n",
    "                # Fetch data using the Hybrid Controller\n",
    "                with st.status(\"Gathering peace...\", expanded=False) as status:\n",
    "                    response = system.get_recommendations(\n",
    "                        user_input=user_mood,\n",
    "                        user_id=st.session_state.user_id,\n",
    "                        just_ate=just_ate,\n",
    "                        hour=hour,\n",
    "                        top_n=4\n",
    "                    )\n",
    "                    st.session_state.results = response.get('recommendations', [])\n",
    "                    st.session_state.current_emotion = response.get('emotion', 'neutral')\n",
    "                    st.session_state.last_mood = user_mood\n",
    "                    st.session_state.last_query_id = query_id\n",
    "                    status.update(label=\"Sanctuary Ready\", state=\"complete\")\n",
    "                \n",
    "                st.empty() # Clear the breathing bubble\n",
    "            st.rerun()\n",
    "\n",
    "    # Results Grid\n",
    "    if st.session_state.results:\n",
    "        st.markdown('<div style=\"margin-top: 5rem; margin-bottom: 3rem; text-align: center;\">', unsafe_allow_html=True)\n",
    "        st.markdown('<h2 style=\"font-size: 2.2rem;\">Curated for you.</h2>', unsafe_allow_html=True)\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "        \n",
    "        results = st.session_state.results\n",
    "        for i in range(0, len(results), 2):\n",
    "            cols = st.columns(2, gap=\"large\")\n",
    "            for j in range(2):\n",
    "                if i + j < len(results):\n",
    "                    vid = results[i+j]\n",
    "                    with cols[j]:\n",
    "                        st.markdown(f\"\"\"\n",
    "                            <div class=\"video-card\">\n",
    "                                <img src=\"{vid['thumbnail']}\" class=\"card-thumb\">\n",
    "                                <div class=\"card-content\">\n",
    "                                    <span class=\"match-pill\">{vid['match_score']}% PERSONAL MATCH</span>\n",
    "                                    <h3 class=\"video-title\">{vid['title']}</h3>\n",
    "                                    <p style=\"color:#6D7275; font-size: 0.9rem;\">{vid['channel_name']}</p>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        \"\"\", unsafe_allow_html=True)\n",
    "                        \n",
    "                        st.video(vid['url'])\n",
    "                        \n",
    "                        # Feedback Loop\n",
    "                        col_stats, col_fb = st.columns([2, 1])\n",
    "                        with col_stats:\n",
    "                            st.markdown(f\"\"\"\n",
    "                                <div style=\"padding: 1rem 0; text-align: left;\">\n",
    "                                    <p style=\"color: #6D7275; font-size: 0.8rem;\">{vid.get('views', 0):,} views \u2022 {vid.get('duration_minutes', 0)} mins</p>\n",
    "                                </div>\n",
    "                            \"\"\", unsafe_allow_html=True)\n",
    "                        \n",
    "                        with col_fb:\n",
    "                            btn_l, btn_r = st.columns(2)\n",
    "                            with btn_l:\n",
    "                                if st.button(\"\ud83d\udc4d\", key=f\"up_{vid['video_id']}_{i+j}\"):\n",
    "                                    system.process_feedback(\n",
    "                                        user_id=st.session_state.user_id,\n",
    "                                        emotion=st.session_state.current_emotion,\n",
    "                                        category='yoga',\n",
    "                                        video_id=vid['video_id'],\n",
    "                                        feedback='thumbs_up',\n",
    "                                        context=vid.get('_context'),\n",
    "                                        video_features=vid.get('features')\n",
    "                                    )\n",
    "                                    st.toast(\"Match perfected! \ud83c\udf3f\")\n",
    "                            with btn_r:\n",
    "                                if st.button(\"\ud83d\udc4e\", key=f\"down_{vid['video_id']}_{i+j}\"):\n",
    "                                    system.process_feedback(\n",
    "                                        user_id=st.session_state.user_id,\n",
    "                                        emotion=st.session_state.current_emotion,\n",
    "                                        category='yoga',\n",
    "                                        video_id=vid['video_id'],\n",
    "                                        feedback='thumbs_down',\n",
    "                                        context=vid.get('_context'),\n",
    "                                        video_features=vid.get('features')\n",
    "                                    )\n",
    "                                    st.toast(\"Adjusting your sanctuary... \ud83d\udd4a\ufe0f\")\n",
    "\n",
    "    # Empty State\n",
    "    elif not user_mood and not st.session_state.results:\n",
    "        st.markdown('<div style=\"height: 10rem;\"></div>', unsafe_allow_html=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}